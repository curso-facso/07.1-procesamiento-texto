---
title: "Métodos computacionales para las ciencias sociales"
subtitle: "Procesamiento de texto"
format: 
    revealjs:
      auto-stretch: false
      scrollable: true
css: style.css
editor: source
execute:
  echo: true
---

## Contenidos de la clase

-   Herramientas del tidyverse para manejo de *strings*
-   Expresiones regulares
-   udpipe

# ¿Por qué es relevante conocer herramientas para manejar *strings*? {.center background-color="aquamarine"}

## Motivación: Funes, el Memorioso

::: panel-tabset
## Borges

![](imagenes/borges.jpg){width="250" fig-align="center"}

## Funes

```{r}
library(pdftools)
funes_bruto <-  pdf_text("data/funes.pdf")
funes_bruto
```

## pre procesamiento

```{r, echo=FALSE}
library(tidyverse)

funes2 <- funes_bruto %>% 
  str_remove(pattern = "Jorge Luis Borges\n\n\n") %>% 
  str_replace_all(pattern = "\n", " ") %>% 
  str_remove(pattern = "Funes, el memorioso" ) %>% 
  str_remove_all(pattern = "  ") %>% 
  str_remove_all("\\\\")

write_csv(data.frame(text = unlist(funes2)) , file = "data/funes_editado.csv")

print(funes2)
```

## sustantivos

```{r, echo=FALSE}
library(udpipe)
model <- udpipe::udpipe_load_model(file = "spanish-gsd-ud-2.5-191206.udpipe")
pos <- udpipe::udpipe_annotate(model, funes2)
pos_df <- as.data.frame(pos)

pos_df %>% 
  filter(upos == "NOUN") %>% 
  pull(token) %>% 
  unique()

```
:::

## Motivación: chilenos en la memoria

**¿Qué recordamos en Wikipedia?**

Social memory about people from a country. The case of notable Chileans in Wikipedia. Wiki Workshop 2024 (Beytía, P., Rojas, C. & Cruz, C 2024 ).

. . .

[Aplicación](https://www.monitorsocial.cl/chilenos)

## Herramientas para trabajar con texto

-   stringr
-   text2vec
-   quanteda
-   tm
-   keras
-   udpipe
-   entre otras...

## Pero antes...

¿Qué es un string?

. . .

Cadena de caracteres

. . .

Se pueden formar con comillas dobles o simples

```{r, echo=TRUE}
print("soy un string")
```

. . .

```{r, echo=TRUE}
print('yo también soy un string')
```

. . .

En R, se implementan mediante la clase character

. . .

```{r, echo=TRUE}
string <- "siento angustia. No sé quién soy" 
print(paste("Programador:", "Take it easy. Eres un", class(string)))
```

```{r}
print("String: Gracias por aliviar mi angustia existencial")
```

## ¿Qué es un string?

Si usamos comillas dobles dentro de un *string*, tendremos problemas

```{r, error=TRUE, echo=TRUE}
print("Vito Corleone lo reprendió, "Nunca digas lo que piensas frente a extraños" ")
```

. . .

```{r, error=TRUE, echo=TRUE}
print('Vito Corleone lo reprendió, "Nunca digas lo que piensas frente a extraños" ')
```

## Impresión de un string

```{r, echo=TRUE}
print('Vito Corleone lo reprendió: "Nunca digas lo que piensas frente a extraños" ')
```

Warning: La representación impresa de un string no siempre coincide con el verdadero string

. . .

Con `writeLines` podemos imprimir mejor

```{r, echo=TRUE}
writeLines('Vito Corleone lo reprendió: "Nunca digas lo que piensas frente a extraños" ')
```

. . .

El *backslash* se agrega debido a que el caracter " tiene una función especial

Más detalles en breve

# stringr {.center background-color="aquamarine"}

## stringr

::: columns
::: {.column width="50%"}
![](imagenes/logo_stringr.png){width="250"}
:::

::: {.column width="50%"}
::: fragment
-   Pertenece al `tidyverse`

-   [Aquí](https://stringr.tidyverse.org/index.html) está la documentación oficial

-   Construido sobre [stringi](https://stringi.gagolewski.com/index.html#)

-   Todas las funciones comienzan con str\_
:::
:::
:::

## Funciones de uso común

-   `str_to_lower`: pasar todo a minúscula
-   `str_sub`: seleccionar parte de un string
-   `str_replace`: reemplazar parte de un string
-   `str_length`: largo de un string
-   `str_detect`: detectar un string
-   `str_extract`: extraer un string
-   `str_split`: dividir un string

. . .

#### Todas las funciones operan vectorizadamente

## stringr en acción

```{r, echo=TRUE}
bandas <-  c("Rush", "Dream Theater", "Tool", "Rage Against the Machine")
```

**str_to_lower**

```{r, echo=TRUE}
str_to_lower(bandas)
```

. . .

**str_sub**

```{r, echo=TRUE}
# Extrar desde la primera posición hasta la segunda posición
# IMPORTANTE: también puedes usar índices negativos
str_sub(bandas, start = 1, end =  2)
```

## stringr en acción

**str_replace**

```{r, echo=TRUE}
str_replace(bandas, pattern = "a", replacement = "x")
```

. . .

**str_length**

```{r, echo=TRUE}
str_length(bandas)
```

. . .

**str_replace_all**

```{r, echo=TRUE}
str_replace_all(bandas, pattern = "a", replacement = "x")
```

## stringr en acción

**str_extract**

```{r, echo=TRUE}
str_extract(bandas, pattern = "a")

```

. . .

**str_split**

```{r, echo=TRUE}
# IMPORTANTE: Genera una lista, cuyos elementos son vectores
str_split(bandas, pattern = " ") 
```

## Ejercicio: Funes, el Memorioso (1)

Con el siguiente código cargamos el texto de *Funes*, ya pre procesado

Descarga los datos [acá](https://1drv.ms/f/c/3ba457a6b989f5e0/EuJyKdmhgW1LvaJ5Nf9qo0YBPQHuDyqukG-z30drWwjrxg?e=c4CDHl)

```{r, echo=TRUE}
library(readr)
funes <-  read_csv("data/funes_editado.csv")
```

1.  Separa el texto usando el carácter de espacio " ". Explora el parámetro simplify
2.  Cuenta el largo de cada una de los *strings* resultantes
3.  Cuenta la cantidad de *strings* resultantes
4.  Calcula el promedio del largo de los *strings*

## Ejercicio: Funes, el Memorioso (1)

Quedan caracteres molestos

```{r}
words <- funes$text %>% 
  str_split(pattern = " ", simplify = F) |> 
  unlist() # desanidamos la lista

filtro <- words %>% str_detect("\\(|\\.")
words[filtro][1:10]
```

Ya nos haremos cargo de esto

## Ejercicio: Funes, el Memorioso (2)

A partir de los *strings* separados:

-   Extrae el primer caracter de cada *string*
-   Extrae los 2 últimos caracteres

# Expresiones regulares {.center background-color="aquamarine"}

## Expresiones regulares: primeros pasos

¿Qué pasa si queremos detectar varios *strings* al mismo tiempo?

. . .

**Ejemplo**: Nos interesa extraer todas las vocales

. . .

Versión carretera

```{r, eval=FALSE, echo=TRUE}
a <- funes2 %>% 
  str_extract_all("a")
e <- funes2 %>% 
  str_extract_all("e")
# etcétera ...

```

. . .

Con expresión regular

```{r, echo=TRUE}
funes2 %>% 
  str_extract_all("a|e|i|o|u")
```

## Explicación regex

Las expresiones regulares permiten buscar o reconocer cadenas de texto de manera muy flexible

. . .

```{r, echo=TRUE}
ejemplo <- c("amigo", "amiga", "Amiga")
str_detect(ejemplo, "(A|a)mig(o|a)")
```

Hay coincidencia en todos los *strings*

## Explicación regex

En general, las expresiones regulares son compartidas entre los lenguajes de programación.

Existe una gran cantidad de expresiones regulares

. . .

```{r, echo=FALSE}
library(kableExtra)
regex <- data.frame(expresion = c("?", "+", "*", "{n}", "{n,m}", "[:digit:]", "[a-z]", "[:alnum:]", "[:punct:]", "."), 
                    descripción = c("El caracter que precede puede aparecer como mucho una vez.",
                                    "El caracter que le precede debe aparecer al menos una vez.",
                                    "El caracter que le precede puede aparecer cero, una, o más veces.",
                                    "Indica que coincide n veces.",
                                    "Indica que coincide mas n veces y menos de m veces.",
                                    "Dígito del 1 al 9",
                                    "Rango de valores",
                                    "Caracteres alfanuméricos",
                                    "Signos de puntuación",
                                    "comodín"
                                                  ))

regex %>% 
  kbl() %>% 
  kable_styling(font_size = 18)
  


```

## Explicación regex

::: panel-tabset
## dígitos

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[:digit:]")

```

## puntuación

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[:punct:]")

```

## rango

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[a-c]")


```
:::

## Patrones más complejos

```{r, echo=TRUE}
# Encontrar un string más complejo
funes2 %>% 
  str_extract_all("(año|en).{1,2}([:digit:])+")
```

## ¿Qué pasa si quiero identificar un caracter especial?

Me interesa trabajar con los paréntesis

. . .

```{r, error=TRUE, echo=TRUE}
funes2 %>% 
  str_count("(")
```

![](https://media.giphy.com/media/UP9ItQNj52DsM3e29m/giphy.gif){width="250"}

## Caracter para escapar

```{r, echo=TRUE}
funes2 %>% 
  str_count("\\(")

```

. . .

El primer *backslash* escapa el significado de ( en la dimensión de expresiones regulares.

Pero *backslash* también es un escape en el mundo de los *strings*

El segundo *backslash* escapa para *strings*

**Consejo: Piensen que el doble *backslash* es la manera de escapar un caracter especial**

## Ejercicio para la casa (1)

::: panel-tabset
## Enríquez

![](imagenes/nuestra-parte-de-noche.jpeg){width="400" fig-align="center"}

## Instrucciones

-   Carga el archivo "Nuestra_parte_de_noche_Mariana_Enriquez.pdf" con la función pdf_text.\
-   Cuenta el número de signos de puntuación que tiene la novela, utilizando la expresión regular \[:punct:\]\
-   Cuenta la cantidad de veces que aparecen las palabras médium y dictadura
:::

```{r, eval=FALSE, echo=FALSE}

mariana <-  pdftools::pdf_text("data/Nuestra_parte_de_noche_Mariana_Enriquez.pdf") 
puntuacion <- mariana %>% 
  str_extract_all("[:punct:]")

medium <- mariana %>% 
  str_count("médium")

sum(medium)
```

## Ejercicio: validando datos

::: panel-tabset
## datos

Una empresa te contacta para trabajar como consultor/a. Al explorar los datos, te das cuenta de que hay problemas con algunas columnas.

```{r, echo=TRUE}
datos <- tribble(~run, ~correo,
        "17.456.987-1", "roberto.bolaño@123cl",
        "15.246123-k",  "parranicanor@hola.cl",
        "14436.987-2",  "woolf_virginiagmail.cl", 
        "18453986-9",   "nonafernandez@hotmail.com",
        "20.456.987-6",  "alejozambra@gmail.com"
        )

```

## ediciones

El mandante te pide hacer la siguiente edición:

-   Crear una nueva variable que contenga el dígito verificador del run (`separate` o `str_split`)

**OJO**: el resultado de `str_split` es una lista anidada

-   Eliminar todos los puntos de la columna *run* (str_remove)
-   Validar que el correo tenga la siguiente estructura: X\@X.X
:::

## No todo envejece bien

En el pasado, el manejo de *strings* era una habilidad escasa

. . .

[GPT](https://chat.openai.com/) resuelve el problema de manera muy sencilla

. . .

Debemos entender el funcionamiento general de las regex

## En conclusión...

Las regex son el primer paso en la exploración y edición de textos

. . .

👀 Las necesitarán para el trabajo 2

. . .

Si `stringr` no tiene lo que necesitan, es muy probable que lo encuentren en `stringi`

. . .

# udpipe: Part of Speech (POS) {.center background-color="aquamarine"}

## Part of Speech

Categorías gramaticales

![](imagenes/pos.jpg){width="880"}

## Part of speech

En español existen 9 categorías gramaticales (en inglés son solo 8)

-   Sustantivo (o nombre)
-   Adjetivo
-   Artículo
-   Pronombre
-   Verbo
-   Adverbio
-   Interjección
-   Preposición
-   Conjunción

## Modelos

Existen modelos de lenguaje entrenados para resolver el etiquetado gramatical

. . .

En R existe un paquete llamado `udpipe`

. . .

Basado en el trabajo de la Charles University (República Checa)

. . .

*Fine tuning* de BERT para la tarea específica de etiquetado POS

. . .

[Acá](https://ufal.mff.cuni.cz/udpipe/2/models) encontrarás la documentación de los modelos

. . .

El valor F1 para la tarea de POS en español es de 99.06

## udpipe: cargando el modelo

```{r, echo=TRUE, eval=T}
#install.packages(udpipe)
library(udpipe)
```

Lo primero que debemos hacer es descargar un modelo

Utilizaremos uno llamado *spanish-ancora*

```{r, eval=FALSE, echo=TRUE}
udpipe_download_model(language = "spanish-ancora")
```

. . .

Luego, podemos cargarlo con `udpipe_load_model`

```{r, eval=TRUE, echo=TRUE}
modelo <- udpipe_load_model("spanish-ancora-ud-2.5-191206.udpipe")
```

## Volvamos a Funes

El texto está cargado en páginas

. . .

Cada página fue cargada como un elemento de una lista

```{r, echo=TRUE}
length(funes_bruto)

```

. . .

Necesitamos tener todo en un solo *string*

```{r, echo=TRUE}
funes_full <- str_flatten(funes_bruto)
length(funes_full)
```

## udpipe: etiquetar

::: panel-tabset
## udpipe

```{r}
funes_procesado <- udpipe_annotate(modelo, x = funes_full)
funes_procesado_df <- as.data.frame(funes_procesado)  %>% 
  select(doc_id:xpos)
```

```{r, echo=FALSE}
library(DT)
funes_procesado_df %>% 
  DT::datatable(rownames = F, 
                options = list(
                  pageLength = 7,
                  dom = "rtip",
                  headerCallback = DT::JS(
                    "function(thead) {",
                    "  $(thead).css('font-size', '0.5em');",
                    "}"
                  ))
                )%>% 
  DT::formatStyle(columns = 1:ncol(funes_procesado_df), fontSize = '40%', backgroundSize = '2%')



```

## token

::: fragment
Unidad de texto
:::

::: fragment
Definición arbitraria
:::

::: fragment
Suele usarse la palabra como unidad básica
:::

::: fragment
Pueden ser secuencias de palabras (2, 3, 4 ... n)
:::

::: fragment
Incluso pueden ser secuencias de caracteres
:::

## conceptos

-   *doc_id*: identificador del texto
-   *paragraph_id*: identificador de párrafo
-   *sentence_id*: identificador de oración
-   *sentence*: oración
-   *token_id*: identificador token
-   *lemma*: forma no flexionada de una palabra
-   *upos*: universal part of speech
-   *xpos*: desagregación de xpos
:::

## Exploremos los resultados

Revisemos este código en RStudio

```{r, eval=FALSE}
# Conteo de categorías 1
funes_procesado_df %>% 
  count(upos) 

# Conteo de categorías 2
funes_procesado_df %>% 
  count(xpos) 

# Tokens más usados
funes_procesado_df %>% 
  count(token) %>% 
  arrange(desc(n))

# Tokens más usados sin puntuación
funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  count(token) %>% 
  arrange(desc(n))

# Cantidad de tokens únicos
length(unique(funes_procesado_df$token))

# Cantidad de lemas únicos
length(unique(funes_procesado_df$lemma))


```

## Eliminando stopwords

A veces, es útil remover *stopwords*

```{r}
funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  count(token) %>% 
  arrange(desc(n)) %>% 
  slice(1:10)

```

. . .

```{r}
library(quanteda)
stop <- quanteda::stopwords("es")

funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  filter(!token %in% stop  ) %>% 
  count(token) %>% 
  arrange(desc(n)) %>% 
  slice(1:5)


```

## Más de un texto

::: panel-tabset
## Qué vergüenza

![](imagenes/portada_que_verguenza.png){width="300"}

## cargar cuentos

```{r, eval=F}
# Cargar libro completo
libro <-  pdf_text("data/Qué vergüenza - Paulina Flores.pdf")

# Seleccionar algunos capítulos
que_verguenza <-  libro[4:13] %>% 
  str_flatten()

talcahuano <- libro[26:43] %>% 
  str_flatten()

cuentos <- c(que_verguenza, talcahuano)

# Procesar con udpipe
cuentos_procesado <- udpipe_annotate(modelo, cuentos)
cuentos_procesado_df <- as.data.frame(cuentos_procesado)  %>% 
  select(doc_id:xpos)


```
:::

## Ejercicio: Qué vergüenza

Comparemos los 2 cuentos de Paulina Flores

Para cada uno de los 2 textos, obtén los siguientes datos:

-   Cantidad de palabras, excluyendo los signos de puntuación
-   Cantidad de palabras únicas, excluyendo los signos de puntuación
-   Cantidad de adjetivos
-   Cantidad de sustantivos
-   Cantidad de signos de puntuación

## Ejemplo final

::: panel-tabset
## Jrushchov

::: columns
::: {.column width="50%"}
![](imagenes/nikita.jpg){fig-align="left"}
:::

::: {.column width="50%"}

**Informe secreto XX Congreso del PCUS**

:::
:::



## limpieza básica

```{r}
informe <-  pdf_text("data/Nikita Khrushchev (1956)_ Informe Secreto al XX Congreso del PCUS_.pdf")

# Aplanamos por conveniencia
informe_flatt <- informe %>% 
  str_flatten()

informe_flatt <- informe_flatt |> 
  str_remove_all("Nikita Khrushchev \\(1956\\): Informe Secreto al XX Congreso del PCUS.")  |> 
  str_remove_all("https://www.marxists.org/espanol/khrushchev/1956/febrero25.htm\\?utm_source=chatgpt.com")


```

## udpipe

```{r}


# Procesar con udpipe
informe_procesado <- udpipe_annotate(modelo, informe_flatt)
informe_procesado_df <- as.data.frame(informe_procesado)  %>% 
  select(doc_id:xpos)






```

## sustantivos propios

```{r}
sustantivos_propios <- informe_procesado_df |> 
   filter(upos == "PROPN")

sustantivos_propios |> 
  count(token)  |> 
  arrange(desc(n)) |> 
  slice(1:10)
```


## adjectivos

```{r}
adjectivos <- informe_procesado_df |> 
   filter(upos == "ADJ")

adjectivos |> 
  count(token)  |> 
  arrange(desc(n)) |> 
  slice(1:10)

```

## totalitario

```{r}
informe_procesado_df |>
  filter(token == "totalitario" | token == "totalitarismo")
```
:::

## Al cierre

Los datos de texto, usualmente, requieren preprocesamiento

. . .

stringr es un gran aliado

. . .

Las expresiones regulares forman parte del cóctel

. . .

**Próxima clase**: vectorización de textos

# Métodos computacionales para las ciencias sociales {.center background-color="aquamarine"}