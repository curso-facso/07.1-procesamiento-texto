---
title: "M√©todos computacionales para las ciencias sociales"
subtitle: "Procesamiento de texto"
format: 
    revealjs:
      auto-stretch: false
      scrollable: true
css: style.css
editor: source
execute:
  echo: true
---



## Contenidos de la clase

-   Herramientas del tidyverse para manejo de *strings*
-   Expresiones regulares
-   udpipe

# ¬øPor qu√© es relevante conocer herramientas para manejar *strings*? {.center background-color="aquamarine"}



## Motivaci√≥n: Funes, el Memorioso


::: panel-tabset
## Funes

```{r}
library(pdftools)
funes_bruto <-  pdf_text("data/funes.pdf")
funes_bruto
```

## pre procesamiento


```{r, echo=FALSE}
library(tidyverse)

funes2 <- funes_bruto %>% 
  str_remove(pattern = "Jorge Luis Borges\n\n\n") %>% 
  str_replace_all(pattern = "\n", " ") %>% 
  str_remove(pattern = "Funes, el memorioso" ) %>% 
  str_remove_all(pattern = "  ") %>% 
  str_remove_all("\\\\")

write_csv(data.frame(text = unlist(funes2)) , file = "data/funes_editado.csv")

print(funes2)
```

## sustantivos

```{r, echo=FALSE}
library(udpipe)
model <- udpipe::udpipe_load_model(file = "spanish-gsd-ud-2.5-191206.udpipe")
pos <- udpipe::udpipe_annotate(model, funes2)
pos_df <- as.data.frame(pos)

pos_df %>% 
  filter(upos == "NOUN") %>% 
  pull(token) %>% 
  unique()

```


:::







## Herramientas para trabajar con texto

-   stringr
-   text2vec
-   quanteda
-   tm
-   keras
-   udpipe
-   entre otras...

## Pero antes...

¬øQu√© es un string?

. . .

Cadena de caracteres

. . .

Se pueden formar con comillas dobles o simples

```{r, echo=TRUE}
print("soy un string")
```

. . .

```{r, echo=TRUE}
print('yo tambi√©n soy un string')
```

. . .

En R, se implementan mediante la clase character

. . .

```{r, echo=TRUE}
string <- "siento angustia. No s√© qui√©n soy" 
print(paste("Programador:", "Take it easy. Eres un", class(string)))
```

```{r}
print("String: Gracias por aliviar mi angustia existencial")
```

## ¬øQu√© es un string?

Si usamos comillas dobles dentro de un *string*, tendremos problemas 

```{r, error=TRUE, echo=TRUE}
print("Vito Corleone lo reprendi√≥, "Nunca digas lo que piensas frente a extra√±os" ")
```

. . .

```{r, error=TRUE, echo=TRUE}
print('Vito Corleone lo reprendi√≥, "Nunca digas lo que piensas frente a extra√±os" ')
```


## Impresi√≥n de un string

```{r, echo=TRUE}
print('Vito Corleone lo reprendi√≥: "Nunca digas lo que piensas frente a extra√±os" ')
```

Warning: La representaci√≥n impresa de un string no siempre coincide con el verdadero string


. . .

Con `writeLines` podemos imprimir mejor  

```{r, echo=TRUE}
writeLines('Vito Corleone lo reprendi√≥: "Nunca digas lo que piensas frente a extra√±os" ')
```


. . .

El *backslash* se agrega debido a que el caracter " tiene una funci√≥n especial

M√°s detalles en breve



# stringr {.center background-color="aquamarine"}

## stringr



::: columns
::: {.column width="50%"}

![](imagenes/logo_stringr.png){width="250"}
:::


::: {.column width="50%"}

::: fragment

- Pertenece al `tidyverse`

- [Aqu√≠](https://stringr.tidyverse.org/index.html) est√° la documentaci√≥n oficial

- Construido sobre [stringi](https://stringi.gagolewski.com/index.html#)

- Todas las funciones comienzan con str_

:::


:::
:::

## Funciones de uso com√∫n

- `str_to_lower`: pasar todo a min√∫scula
- `str_sub`: seleccionar parte de un string
- `str_replace`: reemplazar parte de un string
- `str_length`: largo de un string
- `str_detect`: detectar un string
- `str_extract`: extraer un string
- `str_split`: dividir un string

. . .

#### Todas las funciones operan vectorizadamente


## stringr en acci√≥n

```{r, echo=TRUE}
bandas <-  c("Rush", "Dream Theater", "Tool", "Rage Against the Machine")
```


**str_to_lower**

```{r, echo=TRUE}
str_to_lower(bandas)
```

. . .

**str_sub**

```{r, echo=TRUE}
# Extrar desde la primera posici√≥n hasta la segunda posici√≥n
# IMPORTANTE: tambi√©n puedes usar √≠ndices negativos
str_sub(bandas, start = 1, end =  2)
```

## stringr en acci√≥n


**str_replace**

```{r, echo=TRUE}
str_replace(bandas, pattern = "a", replacement = "x")
```

. . .

**str_length**

```{r, echo=TRUE}
str_length(bandas)
```

. . .

**str_replace_all**

```{r, echo=TRUE}
str_replace_all(bandas, pattern = "a", replacement = "x")
```

## stringr en acci√≥n


**str_extract**

```{r, echo=TRUE}
str_extract(bandas, pattern = "a")

```

. . .

**str_split**

```{r, echo=TRUE}
# IMPORTANTE: Genera una lista, cuyos elementos son vectores
str_split(bandas, pattern = " ") 
```


## Ejercicio: Funes, el Memorioso (parte 1)

Con el siguiente c√≥digo carga el texto de *Funes*, ya pre procesado 

```{r, echo=TRUE}
library(readr)
funes <-  read_csv("data/funes_editado.csv")
```


1. Separa el texto usando el car√°cter de espacio " ". Explora el par√°metro simplify
2. Cuenta el largo de cada una de los *strings* resultantes
3. Cuenta la cantidad de *strings* resultantes 
4. Calcula el promedio del largo de los *strings*

## Ejercicio: Funes, el Memorioso (parte 1)

Quedan caracteres molestos

```{r}
words <- funes$text %>% 
  str_split(pattern = " ", simplify = T) 

filtro <- words %>% str_detect("\\(|\\.")
words[filtro][1:10]
```


Ya nos haremos cargo de esto

## Ejercicio: Funes, el Memorioso (parte 2)

A partir de los *strings* separados:

- Extrae el primer caracter de cada *string*
- Extrae los 2 √∫ltimos caracteres 

# Expresiones regulares {.center background-color="aquamarine"}


## Expresiones regulares: primeros pasos

¬øQu√© pasa si queremos detectar varios *strings* al mismo tiempo?

. . .

**Ejemplo**: Nos interesa extraer todas las vocales

. . .

Versi√≥n carretera

```{r, eval=FALSE, echo=TRUE}
a <- funes2 %>% 
  str_extract_all("a")
e <- funes2 %>% 
  str_extract_all("e")
# etc√©tera ...

```

. . .

Con expresi√≥n regular

```{r, echo=TRUE}
funes2 %>% 
  str_extract_all("a|e|i|o|u")
```

## Explicaci√≥n regex

Las expresiones regulares permiten buscar o reconocer cadenas de texto de manera muy flexible

. . .

```{r, echo=TRUE}
ejemplo <- c("amigo", "amiga", "Amiga")
str_detect(ejemplo, "(A|a)mig(o|a)")
```

Hay coincidencia en todos los *strings*


## Explicaci√≥n regex

En general, las expresiones regulares son compartidas entre los lenguajes de programaci√≥n. 

Existe una gran cantidad de expresiones regulares

. . .

```{r, echo=FALSE}
library(kableExtra)
regex <- data.frame(expresion = c("?", "+", "*", "{n}", "{n,m}", "[:digit:]", "[a-z]", "[:alnum:]", "[:punct:]", "."), 
                    descripci√≥n = c("El caracter que precede puede aparecer como mucho una vez.",
                                    "El caracter que le precede debe aparecer al menos una vez.",
                                    "El caracter que le precede puede aparecer cero, una, o m√°s veces.",
                                    "Indica que coincide n veces.",
                                    "Indica que coincide mas n veces y menos de m veces.",
                                    "D√≠gito del 1 al 9",
                                    "Rango de valores",
                                    "Caracteres alfanum√©ricos",
                                    "Signos de puntuaci√≥n",
                                    "comod√≠n"
                                                  ))

regex %>% 
  kbl() %>% 
  kable_styling(font_size = 18)
  


```

## Explicaci√≥n regex

::: panel-tabset
## d√≠gitos

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[:digit:]")

```

## puntuaci√≥n

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[:punct:]")

```

## rango

```{r, echo=TRUE}
funes2[[1]] %>% 
  str_extract_all("[a-c]")


```

:::

## Patrones m√°s complejos


```{r, echo=TRUE}
# Encontrar un string m√°s complejo
funes2 %>% 
  str_extract_all("(a√±o|en).{1,2}([:digit:])+")
```

## ¬øQu√© pasa si quiero identificar un caracter especial?

Me interesa trabajar con los par√©ntesis

. . .

```{r, error=TRUE, echo=TRUE} 
funes2 %>% 
  str_count("(")
```

![](https://media.giphy.com/media/UP9ItQNj52DsM3e29m/giphy.gif){width="250"}

## Caracter para escapar

```{r, echo=TRUE}
funes2 %>% 
  str_count("\\(")

```
. . .

El primer *backslash* escapa el significado de ( en la dimensi√≥n de expresiones regulares.

Pero *backslash* tambi√©n es un escape en el mundo de los *strings* 

El segundo *backslash* escapa para *strings*  

**Consejo: Piensen que el doble *backslash* es la manera de escapar un caracter especial**

## Ejercicio: validando datos

::: panel-tabset
## datos

Una empresa te contacta para trabajar como consultor/a. Al explorar los datos, te das cuenta de que hay problemas con algunas columnas.

```{r, echo=TRUE}
datos <- tribble(~run, ~correo,
        "17.456.987-1", "roberto.bola√±o@123cl",
        "15.246123-k",  "parranicanor@hola.cl",
        "14436.987-2",  "woolf_virginiagmail.cl", 
        "18453986-9",   "nonafernandez@hotmail.com",
        "20.456.987-6",  "alejozambra@gmail.com"
        )

```

## ediciones

El mandante te pide hacer la siguiente edici√≥n:

- Crear una nueva variable que contenga el d√≠gito verificador del run (`separate` o  `str_split`)

**OJO**: el resultado de `str_split` es una lista anidada

- Eliminar todos los puntos de la columna *run* (str_remove)
- Validar que el correo tenga la siguiente estructura: X@X.X 

:::

## No todo envejece bien

En el pasado, el manejo de *strings* era una habilidad escasa

. . .

[GPT-3](https://chat.openai.com/) resuelve el problema de manera muy sencilla

. . .

Debemos entender el funcionamiento general de las regex 

## En conclusi√≥n...

Las regex son el primer paso en la exploraci√≥n y edici√≥n de textos

. . .

üëÄ Las necesitar√°n para el trabajo 2

. . .

Si `stringr` no tiene lo que necesitan, es muy probable que lo encuentren en `stringi`

. . .


# udpipe: Part of Speech (POS) {.center background-color="aquamarine"}


## Part of Speech

Categor√≠as gramaticales

![](imagenes/pos.jpg){width="880"}


## Part of speech

En espa√±ol existen 9 categor√≠as gramaticales (en ingl√©s son solo 8)

- Sustantivo (o nombre)
- Adjetivo
- Art√≠culo
- Pronombre
- Verbo
- Adverbio
- Interjecci√≥n
- Preposici√≥n
- Conjunci√≥n

## Modelos

Existen modelos de lenguaje entrenados para resolver el etiquetado gramatical

. . .

En R existe un paquete llamado `udpipe`

. . .

Basado en el trabajo de la Charles University (Rep√∫blica Checa)

. . .

*Fine tuning* de BERT para la tarea espec√≠fica de etiquetado POS 

. . .

[Ac√°](https://ufal.mff.cuni.cz/udpipe/2/models) encontrar√°s la documentaci√≥n de los modelos

. . .

El valor F1 para la tarea de POS en espa√±ol es de 99.06 

## udpipe: cargando el modelo

```{r, echo=TRUE, eval=T}
#install.packages(udpipe)
library(udpipe)
```

Lo primero que debemos hacer es descargar un modelo 

Utilizaremos uno llamado *spanish-ancora*

```{r, eval=FALSE, echo=TRUE}
udpipe_download_model(language = "spanish-ancora")
```

. . .

Luego, podemos cargarlo con `udpipe_load_model`

```{r, eval=TRUE, echo=TRUE}
modelo <- udpipe_load_model("spanish-ancora-ud-2.5-191206.udpipe")
```


## Volvamos a Funes

El texto est√° cargado en p√°ginas

. . .

Cada p√°gina fue cargada como un elemento de una lista

```{r, echo=TRUE}
length(funes_bruto)

```

. . .

Necesitamos tener todo en un solo *string*

```{r, echo=TRUE}
funes_full <- str_flatten(funes_bruto)
length(funes_full)
```

 

## udpipe: etiquetar 


::: panel-tabset
## udpipe

```{r}
funes_procesado <- udpipe_annotate(modelo, x = funes_full)
funes_procesado_df <- as.data.frame(funes_procesado)  %>% 
  select(doc_id:xpos)
```

```{r, echo=FALSE}
library(DT)
funes_procesado_df %>% 
  DT::datatable(rownames = F, 
                options = list(
                  pageLength = 7,
                  dom = "rtip",
                  headerCallback = DT::JS(
                    "function(thead) {",
                    "  $(thead).css('font-size', '0.5em');",
                    "}"
                  ))
                )%>% 
  DT::formatStyle(columns = 1:ncol(funes_procesado_df), fontSize = '40%', backgroundSize = '2%')



```


## token


::: fragment
Unidad de texto
:::

::: fragment
Definici√≥n arbitraria
:::

::: fragment
Suele usarse la palabra como unidad b√°sica
:::

::: fragment
Pueden ser secuencias de palabras (2, 3, 4 ... n) 
:::

::: fragment
Incluso pueden ser secuencias de caracteres
:::

## conceptos

- *doc_id*: identificador del texto
- *paragraph_id*: identificador de p√°rrafo
- *sentence_id*: identificador de oraci√≥n
- *sentence*: oraci√≥n 
- *token_id*: identificador token
- *lemma*: forma no flexionada de una palabra
- *upos*: universal part of speech
- *xpos*: desagregaci√≥n de xpos


:::


## Exploremos los resultados

Revisemos este c√≥digo en RStudio

```{r, eval=FALSE}
# Conteo de categor√≠as 1
funes_procesado_df %>% 
  count(upos) 

# Conteo de categor√≠as 2
funes_procesado_df %>% 
  count(xpos) 

# Tokens m√°s usados
funes_procesado_df %>% 
  count(token) %>% 
  arrange(desc(n))

# Tokens m√°s usados sin puntuaci√≥n
funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  count(token) %>% 
  arrange(desc(n))

# Cantidad de tokens √∫nicos
length(unique(funes_procesado_df$token))

# Cantidad de lemas √∫nicos
length(unique(funes_procesado_df$lemma))


```

## Eliminando stopwords

A veces, es √∫til remover *stopwords*

```{r}
funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  count(token) %>% 
  arrange(desc(n)) %>% 
  slice(1:10)

```


. . .

```{r}
library(quanteda)
stop <- quanteda::stopwords("es")

funes_procesado_df %>%
  filter(upos != "PUNCT") %>% 
  filter(!token %in% stop  ) %>% 
  count(token) %>% 
  arrange(desc(n)) %>% 
  slice(1:5)


```



## M√°s de un texto

::: panel-tabset

## Qu√© verg√ºenza

![](imagenes/portada_que_verguenza.png){width="300"}

## cargar cuentos 

```{r, eval=F}
# Cargar libro completo
libro <-  pdf_text("data/Qu√© verg√ºenza - Paulina Flores.pdf")

# Seleccionar algunos cap√≠tulos
que_verguenza <-  libro[4:13] %>% 
  str_flatten()

talcahuano <- libro[26:43] %>% 
  str_flatten()

cuentos <- c(que_verguenza, talcahuano)

# Procesar con udpipe
cuentos_procesado <- udpipe_annotate(modelo, cuentos)
cuentos_procesado_df <- as.data.frame(cuentos_procesado)  %>% 
  select(doc_id:xpos)


```



:::

## Ejercicio: Qu√© verg√ºenza

Comparemos los 2 cuentos de Paulina Flores

Para cada uno de los 2 textos, obt√©n los siguientes datos:

- Cantidad de palabras, excluyendo los signos de puntuaci√≥n
- Cantidad de palabras √∫nicas, excluyendo los signos de puntuaci√≥n
- Cantidad de adjetivos 
- Cantidad de sustantivos
- Cantidad de signos de puntuaci√≥n 


## Al cierre

Los datos de texto, usualmente, requieren preprocesamiento

. . .

stringr es un gran aliado

. . .

Las expresiones regulares forman parte del c√≥ctel

. . .

**Pr√≥xima clase**: vectorizaci√≥n de textos



# M√©todos computacionales para las ciencias sociales {.center background-color="aquamarine"}
